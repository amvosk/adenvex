{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\smiles\\Lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import einops\n",
    "\n",
    "import numpy as np\n",
    "import scipy.signal as sg\n",
    "\n",
    "from envelope_detector import EnvelopeDetector, create_importance_indices, create_spatial_patterns, create_temporal_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff(x, y):\n",
    "    return torch.linalg.norm(x - y) / torch.sqrt(torch.linalg.norm(x) * torch.linalg.norm(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "npoints = 300\n",
    "nchannels = 30\n",
    "nfeatures = 5\n",
    "spatial_bias = False\n",
    "np.random.seed(0)\n",
    "data = np.random.normal(size=(1000, nchannels, npoints))\n",
    "x = einops.rearrange(data, 'b c t -> c (b t)')\n",
    "data_tf = einops.rearrange(data, 'b c t -> b t c')\n",
    "fs = 1000\n",
    "temporal_filter_size = 15\n",
    "temporal_filter_dilation = 2\n",
    "downsample_coef = 10\n",
    "output_layer = 3\n",
    "nyquist = fs // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "envelope_detector = EnvelopeDetector(\n",
    "    nchannels=nchannels, \n",
    "    nfeatures=nfeatures, \n",
    "    temporal_filter_size=temporal_filter_size,\n",
    "    temporal_filter_dilation=temporal_filter_dilation,\n",
    "    downsample_coef=downsample_coef, \n",
    "    fs_in=fs,\n",
    "    spatial_bias=spatial_bias,\n",
    "    activation='demodulation', \n",
    "    downsample_method='avepool',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_filters = envelope_detector.get_spatial_filter()\n",
    "\n",
    "temporal_filters = envelope_detector.get_temporal_filter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dilated_temporal_filter(self):\n",
    "    # Extract the original temporal filter\n",
    "    original_filter = self.get_temporal_filter()  # Shape [nfeatures, temporal_filter_size]\n",
    "\n",
    "    # Calculate the size of the dilated filter\n",
    "    dilated_filter_size = 1 + (original_filter.shape[1] - 1) * self.temporal_filter_dilation\n",
    "\n",
    "    # Initialize a new tensor for the dilated filter with zeros\n",
    "    dilated_filter = torch.zeros(original_filter.shape[0], dilated_filter_size)\n",
    "\n",
    "    # Set the appropriate values from the original filter to the dilated filter\n",
    "    for i in range(original_filter.shape[1]):\n",
    "        dilated_filter[:, i * self.temporal_filter_dilation] = original_filter[:, i]\n",
    "\n",
    "    return dilated_filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilated_filter_size = 1 + (temporal_filters.shape[1] - 1) * temporal_filter_dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilated_filter = torch.zeros(temporal_filters.shape[0], dilated_filter_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(temporal_filters.shape[1]):\n",
    "    dilated_filter[:, i * temporal_filter_dilation] = temporal_filters[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1681,  0.0000,  0.0000,  0.1242,  0.0000,  0.0000, -0.0336,  0.0000,\n",
       "          0.0000,  0.2123,  0.0000,  0.0000,  0.1994,  0.0000,  0.0000, -0.1070,\n",
       "          0.0000,  0.0000, -0.1436,  0.0000,  0.0000, -0.1387,  0.0000,  0.0000,\n",
       "          0.1567,  0.0000,  0.0000, -0.2483,  0.0000,  0.0000, -0.1231,  0.0000,\n",
       "          0.0000, -0.1509,  0.0000,  0.0000, -0.2406,  0.0000,  0.0000,  0.1104,\n",
       "          0.0000,  0.0000, -0.0830],\n",
       "        [ 0.0548,  0.0000,  0.0000, -0.2452,  0.0000,  0.0000, -0.0948,  0.0000,\n",
       "          0.0000, -0.1688,  0.0000,  0.0000,  0.1216,  0.0000,  0.0000,  0.1904,\n",
       "          0.0000,  0.0000,  0.2102,  0.0000,  0.0000, -0.2420,  0.0000,  0.0000,\n",
       "         -0.1556,  0.0000,  0.0000,  0.2002,  0.0000,  0.0000, -0.1933,  0.0000,\n",
       "          0.0000,  0.1583,  0.0000,  0.0000,  0.0232,  0.0000,  0.0000, -0.2525,\n",
       "          0.0000,  0.0000, -0.0394],\n",
       "        [-0.0148,  0.0000,  0.0000, -0.1006,  0.0000,  0.0000, -0.0755,  0.0000,\n",
       "          0.0000,  0.0339,  0.0000,  0.0000, -0.1491,  0.0000,  0.0000, -0.1992,\n",
       "          0.0000,  0.0000,  0.2319,  0.0000,  0.0000, -0.0780,  0.0000,  0.0000,\n",
       "          0.0467,  0.0000,  0.0000,  0.0041,  0.0000,  0.0000,  0.2199,  0.0000,\n",
       "          0.0000,  0.0855,  0.0000,  0.0000,  0.1214,  0.0000,  0.0000, -0.0851,\n",
       "          0.0000,  0.0000,  0.0777],\n",
       "        [ 0.1846,  0.0000,  0.0000, -0.0311,  0.0000,  0.0000, -0.2291,  0.0000,\n",
       "          0.0000, -0.1696,  0.0000,  0.0000,  0.1923,  0.0000,  0.0000, -0.1040,\n",
       "          0.0000,  0.0000, -0.0215,  0.0000,  0.0000,  0.0096,  0.0000,  0.0000,\n",
       "         -0.0931,  0.0000,  0.0000,  0.2417,  0.0000,  0.0000,  0.0032,  0.0000,\n",
       "          0.0000,  0.1442,  0.0000,  0.0000, -0.2565,  0.0000,  0.0000, -0.0542,\n",
       "          0.0000,  0.0000,  0.1822],\n",
       "        [ 0.0789,  0.0000,  0.0000, -0.1282,  0.0000,  0.0000,  0.0252,  0.0000,\n",
       "          0.0000, -0.1824,  0.0000,  0.0000,  0.0406,  0.0000,  0.0000, -0.1955,\n",
       "          0.0000,  0.0000, -0.1642,  0.0000,  0.0000,  0.0215,  0.0000,  0.0000,\n",
       "         -0.1363,  0.0000,  0.0000, -0.1123,  0.0000,  0.0000, -0.0574,  0.0000,\n",
       "          0.0000, -0.0475,  0.0000,  0.0000,  0.1659,  0.0000,  0.0000, -0.2507,\n",
       "          0.0000,  0.0000,  0.1471]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dilated_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance(x, unbiased=True, mean=None):\n",
    "    if mean is None:\n",
    "        mean = torch.mean(x, dim=-1, keepdims=True)\n",
    "    x = x - mean\n",
    "    covariance_matrix = 1 / (x.shape[-1] - unbiased) * torch.einsum('...ct, ...Ct -> ...cC', x, x)\n",
    "    return covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_patterns = torch.zeros((nfeatures, nchannels), dtype=torch.float32)\n",
    "\n",
    "for feature in range(nfeatures):\n",
    "    temporal_filter = envelope_detector.temporal_filter.weight.data[feature:feature+1]\n",
    "    spatial_filter = envelope_detector.spatial_filter.weight.data[feature]\n",
    "    temporal_filter_ = einops.repeat(temporal_filter, '1 1 t -> c 1 t', c=nchannels)\n",
    "    \n",
    "    x_filtered = F.conv1d(torch.tensor(x, dtype=torch.float32), temporal_filter_, bias=None, padding='same', groups=nchannels)\n",
    "    x_cov = covariance(x_filtered, unbiased=True)\n",
    "\n",
    "    pattern = torch.einsum('...cC, Ck -> c', x_cov, spatial_filter)\n",
    "    spatial_patterns[feature] = pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(0.0013)\n"
     ]
    }
   ],
   "source": [
    "spatial_results_x = create_spatial_patterns(x, spatial_filters, temporal_filters)\n",
    "spatial_results_data = create_spatial_patterns(data, spatial_filters, temporal_filters, nbatch=10)\n",
    "\n",
    "print(diff(spatial_patterns, spatial_results_x['spatial_patterns']))\n",
    "print(diff(spatial_patterns, spatial_results_data['spatial_patterns']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrum(signal, fs, nfreq):\n",
    "    amplitudes = torch.abs(torch.fft.fft(signal, nfreq, dim=-1))\n",
    "    frequencies = torch.fft.fftfreq(nfreq, d=1/fs)\n",
    "    assert amplitudes.shape[-1] == frequencies.shape[-1], f\"{amplitudes.shape[-1]}!={frequencies.shape[-1]}\"\n",
    "    positive_freq = nfreq // 2\n",
    "    return frequencies[:positive_freq], amplitudes[...,:positive_freq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_unmixed = envelope_detector.spatial_filter(torch.tensor(x, dtype=torch.float32))\n",
    "temporal_filter = envelope_detector.temporal_filter.weight.data\n",
    "\n",
    "x_unmixed_numpy = x_unmixed.cpu().detach().numpy()\n",
    "input_frequencies, input_spectrum = sg.welch(x_unmixed_numpy, fs=fs, nperseg=nyquist, detrend='constant', axis=-1)\n",
    "input_frequencies = torch.tensor(input_frequencies[:-1], dtype=x_unmixed.dtype, device=x_unmixed.device)\n",
    "input_spectrum = torch.tensor(input_spectrum[...,:-1], dtype=x_unmixed.dtype, device=x_unmixed.device)\n",
    "\n",
    "frequencies_filter, temporal_filters_spectrum = spectrum(temporal_filter, fs, nfreq=nyquist)\n",
    "temporal_filters_spectrum = einops.rearrange(temporal_filters_spectrum, 'c 1 t -> c t')\n",
    "\n",
    "temporal_filters_spectrum = temporal_filters_spectrum\n",
    "temporal_patterns_spectrum = temporal_filters_spectrum * input_spectrum\n",
    "output_spectrum = torch.pow(temporal_filters_spectrum, 2) * input_spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.0086)\n",
      "tensor(0.)\n",
      "tensor(0.0089)\n",
      "tensor(0.0089)\n"
     ]
    }
   ],
   "source": [
    "temporal_results_x = create_temporal_patterns(x, spatial_filters, temporal_filters)\n",
    "temporal_results_data = create_temporal_patterns(data, spatial_filters, temporal_filters, fs=fs, nyquist=nyquist, nbatch=10)\n",
    "\n",
    "print(diff(input_spectrum, temporal_results_x['input_spectrum']))\n",
    "print(diff(temporal_filters_spectrum, temporal_results_x['temporal_filters_spectrum']))\n",
    "print(diff(temporal_patterns_spectrum, temporal_results_x['temporal_patterns_spectrum']))\n",
    "print(diff(output_spectrum, temporal_results_x['output_spectrum']))\n",
    "\n",
    "print(diff(input_spectrum, temporal_results_data['input_spectrum']))\n",
    "print(diff(temporal_filters_spectrum, temporal_results_data['temporal_filters_spectrum']))\n",
    "print(diff(temporal_patterns_spectrum, temporal_results_data['temporal_patterns_spectrum']))\n",
    "print(diff(output_spectrum, temporal_results_data['output_spectrum']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import grad\n",
    "from envelope_detector.utils import SimpleDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Input\n",
    "from tensorflow import keras\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SimpleDataset(data)\n",
    "dataloader = DataLoader(dataset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_tf(npoints, nchannels, nfeatures, temporal_filter_size=7, downsample_coef=1, output_layer=3):\n",
    "    inputs = keras.Input(shape=(npoints, nchannels))\n",
    "    a = layers.Conv1D(nfeatures, 1, padding=\"same\", use_bias=False)(inputs)\n",
    "    b = layers.BatchNormalization(center=False, scale=False, epsilon=1e-5, momentum=0.9)(a, training=False)\n",
    "    c = layers.Conv1D(nfeatures, temporal_filter_size, padding=\"same\", groups=nfeatures, use_bias=False)(b)\n",
    "    d = layers.BatchNormalization(center=False, scale=False, epsilon=1e-5, momentum=0.9)(c, training=False)\n",
    "    e = layers.LeakyReLU(-1)(d)\n",
    "    z = layers.AveragePooling1D(pool_size=downsample_coef, strides=downsample_coef)(e)\n",
    "    y = layers.Conv1D(1, 1, padding=\"same\", use_bias=False)(z)\n",
    "    model = keras.Model(inputs, (a, b, c, d, e, z, y), name=f'tf_model')\n",
    "    model.compile()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_tf_grad(npoints, nchannels, nfeatures, temporal_filter_size=7, downsample_coef=1, output_layer=3):\n",
    "    inputs = keras.Input(shape=(npoints, nchannels))\n",
    "    a = layers.Conv1D(nfeatures, 1, padding=\"same\", use_bias=False)(inputs)\n",
    "    b = layers.BatchNormalization(center=False, scale=False, epsilon=1e-5, momentum=0.9)(a, training=False)\n",
    "    c = layers.Conv1D(nfeatures, temporal_filter_size, padding=\"same\", groups=nfeatures, use_bias=False)(b)\n",
    "    d = layers.BatchNormalization(center=False, scale=False, epsilon=1e-5, momentum=0.9)(c, training=False)\n",
    "    e = layers.LeakyReLU(-1)(d)\n",
    "    z = layers.AveragePooling1D(pool_size=downsample_coef, strides=downsample_coef)(e)\n",
    "    y = layers.Conv1D(1, 1, padding=\"same\", use_bias=False)(z)\n",
    "    model = keras.Model(inputs, (z, y), name=f'tf_model')\n",
    "    model.compile()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(self.__class__,self).__init__()\n",
    "        self.envelope_detector = EnvelopeDetector(**kwargs)\n",
    "        self.regressor = nn.Conv1d(kwargs['nfeatures'], 1, kernel_size=1, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.envelope_detector(x)\n",
    "        y = self.regressor(z)\n",
    "        return z, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf = create_model_tf(\n",
    "    npoints=npoints, \n",
    "    nchannels=nchannels, \n",
    "    nfeatures=nfeatures, \n",
    "    temporal_filter_size=temporal_filter_size, \n",
    "    downsample_coef=downsample_coef, \n",
    "    output_layer=output_layer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "model_pt = SimpleNet(\n",
    "    nchannels=nchannels, \n",
    "    nfeatures=nfeatures, \n",
    "    temporal_filter_size=temporal_filter_size,\n",
    "    downsample_coef=downsample_coef,\n",
    "    spatial_bias=spatial_bias,\n",
    "    activation_method='demodulation', \n",
    "    downsample_method='avepool',\n",
    ")\n",
    "model_pt.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_conv_weights(x):\n",
    "    return einops.rearrange(x, 'k i o -> o i k')\n",
    "\n",
    "spatial_filter = model_pt.envelope_detector.spatial_filter.weight.data.numpy()\n",
    "model_tf.layers[1].set_weights([convert_conv_weights(spatial_filter)])\n",
    "temporal_filter = model_pt.envelope_detector.temporal_filter.weight.data.numpy()\n",
    "model_tf.layers[3].set_weights([convert_conv_weights(temporal_filter)])\n",
    "regressor_filter = model_pt.regressor.weight.data.numpy()\n",
    "model_tf.layers[7].set_weights([convert_conv_weights(regressor_filter)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    a_pt = model_pt.envelope_detector.spatial_filter(torch.tensor(data, dtype=torch.float32))\n",
    "    b_pt = model_pt.envelope_detector.spatial_filter_batchnorm(a_pt)\n",
    "    c_pt = model_pt.envelope_detector.temporal_filter(b_pt)\n",
    "    d_pt = model_pt.envelope_detector.temporal_filter_batchnorm(c_pt)\n",
    "    e_pt = model_pt.envelope_detector.activation(d_pt)\n",
    "    z_pt = model_pt.envelope_detector.downsampler(e_pt)\n",
    "    y_pt = model_pt.regressor(z_pt)\n",
    "    values_pt = [x.numpy() for x in [a_pt, b_pt, c_pt, d_pt, e_pt, z_pt, y_pt]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_tf2pt(x):\n",
    "    return einops.rearrange(x, 'b t c -> b c t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_tf = [tensor_tf2pt(x.numpy()) for x in model_tf(data_tf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.671769476697886e-08\n",
      "7.664036621352898e-08\n",
      "5.291321907243889e-08\n",
      "6.268088330850478e-08\n",
      "6.268088330850478e-08\n",
      "4.170954531752131e-08\n",
      "2.0895071145950377e-08\n"
     ]
    }
   ],
   "source": [
    "for (value_pt, value_tf) in zip(values_pt, values_tf):\n",
    "    print(np.linalg.norm(value_pt - value_tf) / np.sqrt(reduce(lambda x, y: x*y, value_pt.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0895071145950377e-08\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pt_hat = model_pt(torch.tensor(data, dtype=torch.float32))[1].numpy()\n",
    "print(np.linalg.norm(y_pt_hat - list(values_tf)[-1]) / np.sqrt(reduce(lambda x, y: x*y, y_pt_hat.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "model_pt = SimpleNet(\n",
    "    nchannels=nchannels, \n",
    "    nfeatures=nfeatures, \n",
    "    temporal_filter_size=temporal_filter_size,\n",
    "    downsample_coef=downsample_coef,\n",
    "    spatial_bias=spatial_bias,\n",
    "    activation_method='demodulation', \n",
    "    downsample_method='avepool',\n",
    ")\n",
    "model_pt.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_indices_pt, gradients_pt = create_importance_indices(model_pt, data, order=1, nbatch=100, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6646.1860, 9556.2588, 3808.4402, 4501.4277, 1986.8008])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf_grad = create_model_tf_grad(\n",
    "    npoints=npoints, \n",
    "    nchannels=nchannels, \n",
    "    nfeatures=nfeatures, \n",
    "    temporal_filter_size=temporal_filter_size, \n",
    "    downsample_coef=downsample_coef, \n",
    "    output_layer=output_layer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_filter = model_pt.envelope_detector.spatial_filter.weight.data.numpy()\n",
    "model_tf_grad.layers[1].set_weights([convert_conv_weights(spatial_filter)])\n",
    "temporal_filter = model_pt.envelope_detector.temporal_filter.weight.data.numpy()\n",
    "model_tf_grad.layers[3].set_weights([convert_conv_weights(temporal_filter)])\n",
    "regressor_filter = model_pt.regressor.weight.data.numpy()\n",
    "model_tf_grad.layers[7].set_weights([convert_conv_weights(regressor_filter)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_tf, y_tf = model_tf_grad(data_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z_tf, y_tf = model_tf_grad(data_tf)\n",
    "gradients_tf_ = tape.gradient(y_tf, z_tf)\n",
    "gradients_tf = np.sum(np.abs(gradients_tf_), axis=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6646.95  , 9553.332 , 3808.5874, 4502.1646, 1987.5853],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original matrix:\n",
      "tensor([[0.3281, 0.2294, 0.1891, 0.5487],\n",
      "        [0.6804, 0.8202, 0.7929, 0.2544],\n",
      "        [0.7247, 0.4247, 0.9404, 0.0957],\n",
      "        [0.6058, 0.3133, 0.9526, 0.8814]])\n",
      "\n",
      "Matrix after setting diagonal to 10:\n",
      "tensor([[10.0000,  0.2294,  0.1891,  0.5487],\n",
      "        [ 0.6804, 10.0000,  0.7929,  0.2544],\n",
      "        [ 0.7247,  0.4247, 10.0000,  0.0957],\n",
      "        [ 0.6058,  0.3133,  0.9526, 10.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Example matrix\n",
    "matrix = torch.rand(4, 4)\n",
    "print(\"Original matrix:\")\n",
    "print(matrix)\n",
    "\n",
    "# Set all diagonal elements to a value, e.g., 10\n",
    "matrix.fill_diagonal_(10)\n",
    "print(\"\\nMatrix after setting diagonal to 10:\")\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:smiles]",
   "language": "python",
   "name": "conda-env-smiles-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
